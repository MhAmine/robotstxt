% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/robotstxt.R
\name{robotstxt}
\alias{robotstxt}
\title{Generate object representations of a robots.txt file}
\usage{
robotstxt(domain="mydomain.com")
robotstxt(text="User-agent: *\nDisallow: /")
}
\value{
Object (list) of class robotstxt with parsed data from a
  robots.txt file and method(s) for bot permission checking.
}
\description{
Generate object representations of a robots.txt file
}
\section{Fields}{

\describe{
\item{\code{domain}}{character vector holding domain name for which the robots.txt
file is valid; will be set to NA if not supplied on initialization}

\item{\code{text}}{character vector of text of robots.txt file; either supplied on
initializetion or automatically downloaded from domain supplied on
initialization}

\item{\code{bots}}{character vector of bot names mentionend in robots.txt}

\item{\code{permissions}}{data.frame of bot permissions found in robots.txt file}

\item{\code{host}}{data.frame of host fields found in robots.txt file}

\item{\code{sitemap}}{data.frame of sitemap fields found in robots.txt file}

\item{\code{other}}{data.frame of other - none of the above - fields found in
robots.txt file}
}}
\examples{
\dontrun{
rt <- robotstxt(domain="google.com")
rt$bots
rt$permissions
rt$check( paths = c("/", "forbidden"), bot="*")
}

}
\keyword{data}

